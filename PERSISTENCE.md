PERSISTENCE OVERVIEW

This document explains every place we persist state across the TEMPL stack, how XMTP client storage works in Node vs. the browser, what OPFS is, and why this matters for E2E vs. integration tests. If you understand the smart contract but not how XMTP storage/persistence is wired, start here.


What We Persist (And Where)

- Backend DB (web2): SQLite via better-sqlite3
  - File: `backend/groups.db` by default. In E2E we override with `DB_PATH=e2e-groups.db` and clear it when `CLEAR_DB=1`.
  - Tables and meaning:
    - `groups(contract TEXT PRIMARY KEY, groupId TEXT, priest TEXT)`
      - Maps on-chain TEMPL contract address to the XMTP group conversation ID and the priest’s EOA address.
      - Written on POST `/templs` (initial group registration). Re-read at server boot to restore in-memory cache.
    - `mutes(contract TEXT, target TEXT, count INTEGER, until INTEGER, PRIMARY KEY(contract, target))`
      - Stores moderation strikes and mute expiry for each address per TEMPL contract. Written on POST `/mute`.
    - `delegates(contract TEXT, delegate TEXT, PRIMARY KEY(contract, delegate))`
      - Stores which addresses are delegated moderation powers by the priest. Written on POST/DELETE `/delegates`.
  - In-memory cache: a `Map()` mirrors `groups` records with `{ group, groupId, priest }`. The `group` object is the live XMTP group handle. On boot, the server tries to resolve each `groupId` via XMTP and populate the cache.

- XMTP client DB (Node SDK, used by backend and integration tests)
  - Files: `xmtp-<env>-<inboxId>.db3` (+ `-wal`/`-shm`) in the process CWD. You’ll see these at repo root during dev (e.g., `xmtp-dev-<hash>.db3`).
  - Encryption: SQLCipher when a `dbEncryptionKey` is provided (we pass a 32-byte key in Node contexts). The Browser SDK does NOT encrypt (details below).
  - Purpose: stores the client’s identity state, installations, and conversation/message metadata. It is not our schema; it’s managed by the XMTP SDK.
  - Identity model:
    - `inboxId`: stable per “user” on XMTP, derived from the identity ledger for an EOA/SCW.
    - Installations: each inbox can have multiple installations (devices/agents). On the dev network, installs are limited (10 installs per inbox).
    - When creating an XMTP client, the Node SDK locates/creates a local DB for the inboxId and reuses it.

- XMTP client DB (Browser SDK, used by the React app)
  - Storage: OPFS (Origin Private File System) via the browser’s Storage Foundation API.
  - Path: not visible on your OS filesystem; it lives in the browser’s per-origin sandbox. The SDK still names the DB like `xmtp-dev-<inboxId>.db3` but it’s inside OPFS, not on disk.
  - Encryption: none (browser SDK cannot use `dbEncryptionKey` for actual encryption).
  - Important behavior: OPFS uses “synchronous access handles” that are exclusive. If two handles or a writable stream are opened for the same file, further attempts can fail with `NoModificationAllowedError: createSyncAccessHandle` until the handle is released.


Where Data Comes From And Goes

- POST `/templs` (create/register a TEMPL group)
  - Verifies the priest’s signature `create:<contract>`.
  - Creates a new XMTP group with the priest. If `priestInboxId` is provided it is used; otherwise the server resolves the inbox on the XMTP network via `findInboxIdByIdentifier` and waits for identity readiness before inviting. No deterministic/fake inbox IDs are generated by the server.
  - Optionally sets group metadata (name/description), tolerating the SDK’s “success reported as error” edge cases.
  - Sends a warm-up message to introduce initial activity.
  - Persists `{ contract, groupId, priest }` to SQLite and to the in-memory `groups` cache.

- POST `/join` (purchase check + add member to XMTP group)
  - Verifies `join:<contract>` signature.
  - Validates `hasPurchased` against the contract (on-chain read via ethers).
  - Adds the member’s inboxId to the group. If `memberInboxId` is provided, it is used directly; otherwise the server resolves via `findInboxIdByIdentifier` and waits for identity readiness before inviting.
  - Re-syncs and sends a `member-joined` message to give the UI fresh content to discover.
  - Returns `groupId` but does NOT persist membership to our DB (membership is managed by XMTP/the group itself).

- POST `/send` (fallback posting via backend)
  - Tries to send on the server’s group handle. If it can’t (due to eventual consistency), it re-syncs/re-resolves and retries with backoff. No additional persistence.

- POST/DELETE `/delegates`, POST `/mute`
  - Update the SQLite tables as described above.


XMTP Identity, Installations, And Why “Nonce” Exists

- One inboxId per identity (EOA/SCW). That inboxId is the “user” on XMTP. It maps to one or more wallet identities and installations.
- Installations represent devices/agents for the inbox. On the dev network, installs are capped (10). If you keep registering new installations for the same inboxId, you’ll reach “already registered 10/10 installations”.
- The signer’s `getIdentifier()` can include a `nonce`. Changing the nonce is a technique to create/rotate a fresh installation under the same inboxId. Useful when you truly want another device.
- Node SDK vs. Browser SDK:
  - Node: the DB is a real file you can see. Reusing the same `dbEncryptionKey` and inboxId attaches to the existing local database and doesn’t require creating a new installation each time.
  - Browser: the DB is in OPFS and cannot be seen directly by the OS. Repeatedly creating clients with different nonces can create repeated installations, and frequent create/dispose cycles may conflict with OPFS access handles.


What Is OPFS And Why It Matters

- OPFS (Origin Private File System) is a per-origin file system exposed by modern browsers. It’s isolating and persistent; no regular file paths. XMTP Browser SDK uses it to store the SQLite database.
- OPFS provides a “sync access handle” API that gives exclusive access to a file. If your app (or multiple tabs/contexts) try to open a new handle while another one is open (or a writable stream exists), the browser throws `NoModificationAllowedError` when creating the new handle. That’s the error seen in E2E logs.
- Implications:
  - Don’t spin up multiple XMTP clients for the same inboxId concurrently in the browser.
  - Avoid repeatedly creating and tearing down clients in quick succession (especially with storage cleared in between), which increases the chance of handle contention.
  - Prefer a single client per page lifecycle and reuse a stable installation.


Why Integration Passes But E2E Failed

- Integration tests (Vitest)
  - Run entirely in Node. They use the Node SDK for XMTP clients and an in-process backend. The Node SDK writes to on-disk SQLCipher DBs, not OPFS. There are no browser access-handle conflicts.
  - The tests create fresh random wallets (new EOAs) for priest/member/delegate each run, so they don’t hit the dev network’s 10-installation cap.
  - Result: Deterministic, no OPFS, no install exhaustion → group joining passes.

- E2E tests (Playwright)
  - Use the Browser SDK inside Chromium. Our UI previously rotated installation nonces in the browser to “recover” from the dev install cap. Combined with:
    - Reusing the same fixed Hardhat accounts across many runs, and
    - Actively clearing OPFS/IndexedDB between candidate wallets inside the test
  - …this produced two failure modes:
    1) XMTP dev “10/10 installations reached” for the reused wallet’s inboxId, and
    2) OPFS `createSyncAccessHandle` errors due to rapid client re-creation and storage churn during rotation.
  - Result: Client initialization would fail before the app could join the group, causing the test to fail at “Failed to initialize XMTP for any candidate wallet”.


Mitigations And Recommended Patterns

- Stable installation (preferred in browser)
  - Use a stable, persisted nonce per wallet address for Browser SDK clients. Reuse the same installation and OPFS DB across runs. This avoids hitting the install cap and reduces OPFS handle churn.
  - This repo now uses that approach in the app: the nonce is read/written in `localStorage` and reused.

- Ephemeral wallets for tests (simple and robust)
  - Generating a brand-new EOA for the UI per E2E run completely avoids previous installation caps for that address. Fund it from Hardhat, and you’re good to go.
  - Trade-offs:
    - Pros: clean state, no need to rotate installations, no risk of historical caps.
    - Cons: if you depend on reusing the same inboxId for behavior across runs, you lose that continuity (usually fine for tests).
  - We can toggle this in Playwright fixtures to use fresh random wallets instead of fixed Hardhat accounts.

- Avoid aggressive OPFS clearing & multiple client attempts
  - If possible, do not clear OPFS between wallet attempts on the same page. Prefer selecting the wallet once and letting the app reuse the same installation.
  - Ensure one XMTP client per page lifecycle in the browser. If you must switch wallets, fully reload or close the previous client if the SDK exposes it.

- Backend (Node) notes
  - The backend also creates an XMTP Node client. Because the inboxId is stable for the bot’s address, the Node SDK reuses the same local DB between runs. The code includes an installation-rotation fallback but typically does not need to create new installs if the DB and inbox are intact.
  - The backend’s own SQLite (`groups.db`) is unrelated to XMTP’s DB. It’s safe to clear between runs in E2E via `DB_PATH` and `CLEAR_DB` without affecting XMTP identity.


FAQ

- Do we persist chat messages?
  - No. Messages live in XMTP’s network + the client DB (OPFS in browser; SQLCipher DB on Node). Our backend doesn’t store chat messages.

- Where is the “group membership” stored?
  - In XMTP. We only store the mapping from TEMPL contract → `groupId` and the priest address. Adding/removing members happens via the XMTP group APIs and is reflected in the XMTP databases, not our SQLite.

- Why did we see `NoModificationAllowedError` in E2E?
  - That’s OPFS rejecting a new exclusive write handle to the DB while another handle or stream is still open. It’s a browser storage-level contention, not an XMTP core or contract issue.

- Is this a protocol bug?
  - No. Integration proves join works end-to-end at the protocol level using Node SDK. The E2E failures were due to Browser SDK storage/installation patterns and test-time storage manipulation.


Actionable Options For Tests

- Keep the current fix (stable nonce per wallet in the UI) and stop rotating installations.
- Or switch Playwright to fresh random wallets each run:
  - Create new `ethers.Wallet.createRandom()` signers in the fixtures and fund them from Hardhat before the test (approve/mint flows already exist in the spec).
  - This avoids the 10/10 limit entirely for the UI wallet.

Either approach eliminates flakiness without touching core protocol logic.
